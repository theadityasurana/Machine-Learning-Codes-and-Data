{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Remember the code we used with Sklearn to do K Nearest Neighbors? Here it is:"
      ],
      "metadata": {
        "id": "zCzJiA4LuGxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8diR-qBHtgGd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing, cross_validation, neighbors\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('breast-cancer-wisconsin.data.txt')\n",
        "df.replace('?',-99999, inplace=True)\n",
        "df.drop(['id'], 1, inplace=True)\n",
        "\n",
        "X = np.array(df.drop(['class'], 1))\n",
        "y = np.array(df['class'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf = neighbors.KNeighborsClassifier()\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "confidence = clf.score(X_test, y_test)\n",
        "print(confidence)\n",
        "\n",
        "example_measures = np.array([[4,2,1,1,1,2,3,2,1]])\n",
        "example_measures = example_measures.reshape(len(example_measures), -1)\n",
        "prediction = clf.predict(example_measures)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to make only two simple changes here. The first is to import svm from sklearn, and the second is just to use the Support Vector Classifier, which is just svm.SVC. With our changes now:"
      ],
      "metadata": {
        "id": "K309m7R8uKOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing, cross_validation, neighbors, svm\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('breast-cancer-wisconsin.data.txt')\n",
        "df.replace('?',-99999, inplace=True)\n",
        "df.drop(['id'], 1, inplace=True)\n",
        "\n",
        "X = np.array(df.drop(['class'], 1))\n",
        "y = np.array(df['class'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "clf = svm.SVC()\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "confidence = clf.score(X_test, y_test)\n",
        "print(confidence)\n",
        "\n",
        "example_measures = np.array([[4,2,1,1,1,2,3,2,1]])\n",
        "example_measures = example_measures.reshape(len(example_measures), -1)\n",
        "prediction = clf.predict(example_measures)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "NzPmzN2muM23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For me, my output was:\n",
        "\n",
        "\n",
        "0.978571428571\n",
        "\n",
        "[2]\n",
        "Depending on your random sample, you should get something between 94 and 99%, averaging around 97% again. Also, timing the operation, recall that I got 0.044 seconds to execute the KNN code via Scikit-Learn. With the svm.SVC, execution time was a mere 0.00951, which is 4.6x faster on even this very small dataset.\n",
        "\n",
        "\n",
        "So we can agree that the Support Vector Machine appears to get the same accuracy in this case, only at a much faster pace. Note that if we comment out the drop id column part, accuracy goes back down into the 60s. The Support Vector Machine, in general, handles pointless data better than the K Nearest Neighbors algorithm, and definitely will handle outliers better, but, in this example, the meaningless data is still very misleading for us. We are using the default parameters, however. Looking at the Documentation for the Support Vector Classification, there sure are quite a few parameters here that we have no idea what they're doing. In the coming tutorials, we're going to hop in the deep end to pull apart the Support Vector Machine algorithm so we can actually understand what all these parameters mean and how they affect things. While we're breaking things down, start thinking about: How to handle non-linearly seperable data and datasets with more than two classes (since and SVM is a binary classifier, in the sense that it draws a line to divide two groups)."
      ],
      "metadata": {
        "id": "CEo5qs6iuUef"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQjTBwravetK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zACoIbUrve_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beginning SVM from Scratch in Python"
      ],
      "metadata": {
        "id": "S8IqZeSAvfQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "style.use('ggplot')"
      ],
      "metadata": {
        "id": "n95YyPf0vj4K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be using matplotlib to plot and numpy for handling arrays. Next we'll have some starting data:"
      ],
      "metadata": {
        "id": "7PA-hC73vmT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {-1:np.array([[1,7],\n",
        "                          [2,8],\n",
        "                          [3,8],]),\n",
        "\n",
        "             1:np.array([[5,1],\n",
        "                         [6,-1],\n",
        "                         [7,3],])}"
      ],
      "metadata": {
        "id": "H3ETjKxKvoXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to begin building our Support Vector Machine class. If you are not familiar with object oriented programming, don't fret. Our example here will be a very rudimentary form of OOP. Just know that OOP creates objects with attributes, the functions within the class are actually methods, and we use \"self\" on variables that can be referenced anywhere within the class (or object). This is by no means a great explanation, but it should be enough to get you going. If you are confused about the code, just ask!"
      ],
      "metadata": {
        "id": "O3QBOpe4vr4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)"
      ],
      "metadata": {
        "id": "SXLFEYR7vuhT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The __init__ method of a class is one that runs whenever an object is created with the class. The other methods will only run when called to run. For every method, we pass \"self\" as the first parameter mainly out of standards. Next, we are adding a visualization parameter. We're going to want to see the SVM most likely, so we're setting that default to true. Next, you can see some variables like self.color and self.visualization. Doing this will allow us to reference self.colors for example in other methods within our class. Finally, if we have visualization turned on, we're going to begin setting up our graph.\n",
        "\n",
        "Next, let's go ahead and add a couple more methods: fit and predict."
      ],
      "metadata": {
        "id": "bkkR6bYuvw3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)\n",
        "    # train\n",
        "    def fit(self, data):\n",
        "        pass\n",
        "\n",
        "    def predict(self,features):\n",
        "        # sign( x.w+b )\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "\n",
        "        return classification"
      ],
      "metadata": {
        "id": "xksAVVv1vzIv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit method will be used to train our SVM. This will be the optimization step. The predict method will predict the value of a new featureset once we've trained the classifier, which is just the sign(x.w+b) once we know what w and b are.\n",
        "\n",
        "The full code up to this point:"
      ],
      "metadata": {
        "id": "PNbInoqwv1bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "style.use('ggplot')\n",
        "\n",
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)\n",
        "    # train\n",
        "    def fit(self, data):\n",
        "        pass\n",
        "\n",
        "    def predict(self,features):\n",
        "        # sign( x.w+b )\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "\n",
        "        return classification\n",
        "\n",
        "data_dict = {-1:np.array([[1,7],\n",
        "                          [2,8],\n",
        "                          [3,8],]),\n",
        "\n",
        "             1:np.array([[5,1],\n",
        "                         [6,-1],\n",
        "                         [7,3],])}"
      ],
      "metadata": {
        "id": "4lnfN8A-v12s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll begin adding to the fit method:"
      ],
      "metadata": {
        "id": "tEbPjeGEv_5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self, data):\n",
        "        self.data = data\n",
        "        # { ||w||: [w,b] }\n",
        "        opt_dict = {}\n",
        "\n",
        "        transforms = [[1,1],\n",
        "                      [-1,1],\n",
        "                      [-1,-1],\n",
        "                      [1,-1]]"
      ],
      "metadata": {
        "id": "NN5jM85XwB2r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this method is first passing self (remember, just standard to do this with a method), then data is passed. The data is the data we intend to train against / optimize with. In our case, that's going to be data_dict, which we've already created\n",
        "\n",
        "We set self.data to that data. Now, we can reference the training data anywhere else in the class (but again, we'd have to run the train method first with data for it to work without an error)."
      ],
      "metadata": {
        "id": "EHQ66MJVwEv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we begin building an optimization dictionary as opt_dict, which is going to contain any optimization values. As we step down our w vector, we'll test that vector in our constraint function, finding the largest b, if any, that will satisfy the equation, and then we'll store all of that data in our optimization dictionary. The dictionary will be { ||w|| : [w,b] }. When we're all done optimizing, we'll choose the values of w and b for whichever one in the dictionary has the lowest key value (which is ||w||).\n",
        "\n",
        "Finally, we set our transforms. We've explained that our intention there is to make sure we check every version of the vector possible.\n",
        "\n",
        "Next, we need some starting point that matches our data. To do this, we're going to first reference our training data to pick some haflway decent starting values:"
      ],
      "metadata": {
        "id": "20gsTJ5swG_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding values to work with for our ranges.\n",
        "all_data = []\n",
        "for yi in self.data:\n",
        "      for featureset in self.data[yi]:\n",
        "          for feature in featureset:\n",
        "            all_data.append(feature)\n",
        "\n",
        "self.max_feature_value = max(all_data)\n",
        "self.min_feature_value = min(all_data)\n",
        "# no need to keep this memory.\n",
        "all_data=None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Nd4AZCeqwKLU",
        "outputId": "9da42ac9-b345-4e1a-9775-3906a35a30b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4080b1c5650f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# finding values to work with for our ranges.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All we're doing here is cycling through all of our data, and finding the highest and lowest values. Now we're going to work on our step sizes:"
      ],
      "metadata": {
        "id": "29sdBfBUwMte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step_sizes = [self.max_feature_value * 0.1,\n",
        "                      self.max_feature_value * 0.01,\n",
        "                      # starts getting very high cost after this.\n",
        "                      self.max_feature_value * 0.001]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "OHgfcKcKwbgZ",
        "outputId": "68fa6aa4-2515-4db2-89b2-667db8d0de23"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1a5939b52e5f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m step_sizes = [self.max_feature_value * 0.1,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_feature_value\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0;31m# starts getting very high cost after this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       self.max_feature_value * 0.001]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we're doing here is setting some sizes per step that we want to make. For our first pass, we'll take big steps (10%). Once we find the minimum with these steps, we're going to step down to a 1% step size to continue finding the minimum here. Then, one more time, we step down to 0.1% for fine tuning. We could continue stepping down, depending on how precise you want to get. I will discuss towards the end of this project how you could determine within your program whether or not you should continue optimizing or not.\n",
        "\n",
        "Next, we're going to set some variables that will help us make steps with b (used to make larger steps than we use for w, since we care far more about w precision than b), and keep track of the latest optimal value:"
      ],
      "metadata": {
        "id": "tWdCS8BOwexD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extremely expensive\n",
        "b_range_multiple = 5\n",
        "b_multiple = 5\n",
        "latest_optimum = self.max_feature_value*10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "8-TIdPK6wiJp",
        "outputId": "bd8882f2-7666-498a-99f7-374ffd4ee602"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-26444f8439c3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb_range_multiple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb_multiple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlatest_optimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_feature_value\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to begin stepping"
      ],
      "metadata": {
        "id": "QXC8qWJMwqYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in step_sizes:\n",
        "            w = np.array([latest_optimum,latest_optimum])\n",
        "            # we can do this because convex\n",
        "            optimized = False\n",
        "            while not optimized:\n",
        "                pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OpgU1uS6wsV9",
        "outputId": "953bf166-75e3-4f22-e2ef-3b106637c5ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'step_sizes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c19bd645a6fc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstep_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatest_optimum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatest_optimum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;31m# we can do this because convex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0moptimized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptimized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'step_sizes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea here is to begin stepping down the vector. To begin, we'll set optimized to False, and we'll reset this for each major step. The optimized var will be true when we have checked all steps down to the base of the convex shape (our bowl).\n",
        "\n",
        "We will pick up with the logic in the next tutorial, where we actually plug in values to the constraint problem to see if we can find values to save.\n",
        "\n",
        "Full code up to this point:"
      ],
      "metadata": {
        "id": "s8LhN_bnwvuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "style.use('ggplot')\n",
        "\n",
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)\n",
        "    # train\n",
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        # { ||w||: [w,b] }\n",
        "        opt_dict = {}\n",
        "\n",
        "        transforms = [[1,1],\n",
        "                      [-1,1],\n",
        "                      [-1,-1],\n",
        "                      [1,-1]]\n",
        "\n",
        "        all_data = []\n",
        "        for yi in self.data:\n",
        "            for featureset in self.data[yi]:\n",
        "                for feature in featureset:\n",
        "                    all_data.append(feature)\n",
        "\n",
        "        self.max_feature_value = max(all_data)\n",
        "        self.min_feature_value = min(all_data)\n",
        "        all_data = None\n",
        "\n",
        "        step_sizes = [self.max_feature_value * 0.1,\n",
        "                      self.max_feature_value * 0.01,\n",
        "                      # point of expense:\n",
        "                      self.max_feature_value * 0.001,]\n",
        "\n",
        "        # extremely expensive\n",
        "        b_range_multiple = 5\n",
        "        #\n",
        "        b_multiple = 5\n",
        "        latest_optimum = self.max_feature_value*10\n",
        "\n",
        "        for step in step_sizes:\n",
        "            w = np.array([latest_optimum,latest_optimum])\n",
        "            # we can do this because convex\n",
        "            optimized = False\n",
        "            while not optimized:\n",
        "                pass\n",
        "\n",
        "    def predict(self,features):\n",
        "        # sign( x.w+b )\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "\n",
        "        return classification\n",
        "\n",
        "\n",
        "\n",
        "data_dict = {-1:np.array([[1,7],\n",
        "                          [2,8],\n",
        "                          [3,8],]),\n",
        "\n",
        "             1:np.array([[5,1],\n",
        "                         [6,-1],\n",
        "                         [7,3],])}"
      ],
      "metadata": {
        "id": "tEUnYqTlwy_5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Picking up with the while not optimized part:"
      ],
      "metadata": {
        "id": "qaCgBIQ8w6p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized = False\n",
        "while not optimized:\n",
        "  for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
        "                       self.max_feature_value*b_range_multiple,\n",
        "                           step*b_multiple):"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "D0y2uvHdw9h1",
        "outputId": "79cf5eb3-b713-4bdb-fd2e-832daa79ce29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-17-fea9f8971e12>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-fea9f8971e12>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    step*b_multiple):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we begin also iterating through possible b values, and now you can see our b values we set earlier in action. I will note here that we're straight iterating through b with a constant step-size. We could also break down b steps just like we did with w. To make things more accurate and precise, you probably would want to implement that. That said, I am going to skip doing that for brevity, since we'll achieve similar results either way and we're not trying to win any awards here.\n",
        "\n",
        "Adding furhter:"
      ],
      "metadata": {
        "id": "-nH5CGTWxHEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "            optimized = False\n",
        "            while not optimized:\n",
        "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
        "                                   self.max_feature_value*b_range_multiple,\n",
        "                                   step*b_multiple):\n",
        "                    for transformation in transforms:\n",
        "                        w_t = w*transformation\n",
        "                        found_option = True\n",
        "                        # weakest link in the SVM fundamentally\n",
        "                        # SMO attempts to fix this a bit\n",
        "                        # yi(xi.w+b) >= 1\n",
        "                        #\n",
        "                        # #### add a break here later..\n",
        "                        for i in self.data:\n",
        "                            for xi in self.data[i]:\n",
        "                                yi=i\n",
        "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
        "                                    found_option = False\n",
        "\n",
        "                        if found_option:\n",
        "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "pFYoQtSixJY4",
        "outputId": "195059be-f649-4102-9ec5-58ab048b7e34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4d504ac2efab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptimized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n\u001b[0m\u001b[1;32m      4\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_feature_value\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb_range_multiple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        step*b_multiple):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we iterate through each of the transformations, testing each of them against our constraint requirements. If any of the featuresets within our data don't meet our constraints, then we toss the variables as they don't fit and we move on. I commented in a suggestion for a break here. If just one variable doesn't work you might as well give up on the rest since just 1 that doesn't fit is enough to toss the values for w and b. You could break there, as well as in the preceeding for loop. For now, I will leave the code as I originally had it, but I thought of the change whenever I was filming the video version.\n",
        "\n",
        "Now we finish off the fit method, which I will post in full and explain the additions:"
      ],
      "metadata": {
        "id": "ZD6JbihixM1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        # { ||w||: [w,b] }\n",
        "        opt_dict = {}\n",
        "\n",
        "        transforms = [[1,1],\n",
        "                      [-1,1],\n",
        "                      [-1,-1],\n",
        "                      [1,-1]]\n",
        "\n",
        "        all_data = []\n",
        "        for yi in self.data:\n",
        "            for featureset in self.data[yi]:\n",
        "                for feature in featureset:\n",
        "                    all_data.append(feature)\n",
        "\n",
        "        self.max_feature_value = max(all_data)\n",
        "        self.min_feature_value = min(all_data)\n",
        "        all_data = None\n",
        "\n",
        "        # support vectors yi(xi.w+b) = 1\n",
        "\n",
        "\n",
        "        step_sizes = [self.max_feature_value * 0.1,\n",
        "                      self.max_feature_value * 0.01,\n",
        "                      # point of expense:\n",
        "                      self.max_feature_value * 0.001,]\n",
        "\n",
        "\n",
        "\n",
        "        # extremely expensive\n",
        "        b_range_multiple = 5\n",
        "        # we dont need to take as small of steps\n",
        "        # with b as we do w\n",
        "        b_multiple = 5\n",
        "        latest_optimum = self.max_feature_value*10\n",
        "\n",
        "        for step in step_sizes:\n",
        "            w = np.array([latest_optimum,latest_optimum])\n",
        "            # we can do this because convex\n",
        "            optimized = False\n",
        "            while not optimized:\n",
        "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
        "                                   self.max_feature_value*b_range_multiple,\n",
        "                                   step*b_multiple):\n",
        "                    for transformation in transforms:\n",
        "                        w_t = w*transformation\n",
        "                        found_option = True\n",
        "                        # weakest link in the SVM fundamentally\n",
        "                        # SMO attempts to fix this a bit\n",
        "                        # yi(xi.w+b) >= 1\n",
        "                        #\n",
        "                        # #### add a break here later..\n",
        "                        for i in self.data:\n",
        "                            for xi in self.data[i]:\n",
        "                                yi=i\n",
        "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
        "                                    found_option = False\n",
        "\n",
        "                        if found_option:\n",
        "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
        "\n",
        "                if w[0] < 0:\n",
        "                    optimized = True\n",
        "                    print('Optimized a step.')\n",
        "                else:\n",
        "                    w = w - step\n",
        "\n",
        "            norms = sorted([n for n in opt_dict])\n",
        "            #||w|| : [w,b]\n",
        "            opt_choice = opt_dict[norms[0]]\n",
        "            self.w = opt_choice[0]\n",
        "            self.b = opt_choice[1]\n",
        "            latest_optimum = opt_choice[0][0]+step*2"
      ],
      "metadata": {
        "id": "1bVABHrBxPur"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we've passed zero with our stepping of the w vector, there's no reason to continue since we've tested the negatives via the transformation, thus we'll be done with that step size and either continue to the next, or be done entirely. If we've not passed 0, then we take another step. Once we've taken all of the steps that we want to take, then we're going to sort a list of all dictionary keys from our opt_dict (which contains ||w|| : [w,b]). We want the smallest magnitude of vector w, so we go with the first item in that list. We set self.w and self.b from here, we set latest optimums, and we either may take another step or be totally done with the entire process (if we have no more steps to take).\n",
        "\n",
        "At this point, our full code:"
      ],
      "metadata": {
        "id": "8CF3G_xYxSwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "style.use('ggplot')\n",
        "\n",
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)\n",
        "    # train\n",
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        # { ||w||: [w,b] }\n",
        "        opt_dict = {}\n",
        "\n",
        "        transforms = [[1,1],\n",
        "                      [-1,1],\n",
        "                      [-1,-1],\n",
        "                      [1,-1]]\n",
        "\n",
        "        all_data = []\n",
        "        for yi in self.data:\n",
        "            for featureset in self.data[yi]:\n",
        "                for feature in featureset:\n",
        "                    all_data.append(feature)\n",
        "\n",
        "        self.max_feature_value = max(all_data)\n",
        "        self.min_feature_value = min(all_data)\n",
        "        all_data = None\n",
        "\n",
        "        # support vectors yi(xi.w+b) = 1\n",
        "\n",
        "\n",
        "        step_sizes = [self.max_feature_value * 0.1,\n",
        "                      self.max_feature_value * 0.01,\n",
        "                      # point of expense:\n",
        "                      self.max_feature_value * 0.001,]\n",
        "\n",
        "\n",
        "\n",
        "        # extremely expensive\n",
        "        b_range_multiple = 5\n",
        "        # we dont need to take as small of steps\n",
        "        # with b as we do w\n",
        "        b_multiple = 5\n",
        "        latest_optimum = self.max_feature_value*10\n",
        "\n",
        "        for step in step_sizes:\n",
        "            w = np.array([latest_optimum,latest_optimum])\n",
        "            # we can do this because convex\n",
        "            optimized = False\n",
        "            while not optimized:\n",
        "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
        "                                   self.max_feature_value*b_range_multiple,\n",
        "                                   step*b_multiple):\n",
        "                    for transformation in transforms:\n",
        "                        w_t = w*transformation\n",
        "                        found_option = True\n",
        "                        # weakest link in the SVM fundamentally\n",
        "                        # SMO attempts to fix this a bit\n",
        "                        # yi(xi.w+b) >= 1\n",
        "                        #\n",
        "                        # #### add a break here later..\n",
        "                        for i in self.data:\n",
        "                            for xi in self.data[i]:\n",
        "                                yi=i\n",
        "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
        "                                    found_option = False\n",
        "\n",
        "                        if found_option:\n",
        "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
        "\n",
        "                if w[0] < 0:\n",
        "                    optimized = True\n",
        "                    print('Optimized a step.')\n",
        "                else:\n",
        "                    w = w - step\n",
        "\n",
        "            norms = sorted([n for n in opt_dict])\n",
        "            #||w|| : [w,b]\n",
        "            opt_choice = opt_dict[norms[0]]\n",
        "            self.w = opt_choice[0]\n",
        "            self.b = opt_choice[1]\n",
        "            latest_optimum = opt_choice[0][0]+step*2\n",
        "\n",
        "\n",
        "    def predict(self,features):\n",
        "        # sign( x.w+b )\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "        return classification\n",
        "\n",
        "\n",
        "data_dict = {-1:np.array([[1,7],\n",
        "                          [2,8],\n",
        "                          [3,8],]),\n",
        "\n",
        "             1:np.array([[5,1],\n",
        "                         [6,-1],\n",
        "                         [7,3],])}"
      ],
      "metadata": {
        "id": "DP8_XERzxVjN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization and Predicting with our Custom SVM"
      ],
      "metadata": {
        "id": "9cksDIj0xxJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already have a predict method, since that is a fairly easy step, but now we're going to add a bit to it to handle for visualizing the predictions:"
      ],
      "metadata": {
        "id": "RsyzWdkEx0bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self,features):\n",
        "        # classifiction is just:\n",
        "        # sign(xi.w+b)\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "        # if the classification isn't zero, and we have visualization on, we graph\n",
        "        if classification != 0 and self.visualization:\n",
        "            self.ax.scatter(features[0],features[1],s=200,marker='*', c=self.colors[classification])\n",
        "        else:\n",
        "            print('featureset',features,'is on the decision boundary')\n",
        "        return classification"
      ],
      "metadata": {
        "id": "cf1812JQx2kb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, all we've added is handling to also visualize the prediction if we have one. We're just going to do one at a time, but you could augment the code to do many at once like scikit-learn does.\n",
        "\n",
        "Next, let's begin building our visualize method:"
      ],
      "metadata": {
        "id": "neke5JxAx5L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(self):\n",
        "        #scattering known featuresets.\n",
        "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "nAL62N8kx76o",
        "outputId": "bd0c533d-aae5-4c5b-e1be-5ddab45d972b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-22-8b1e62185e77>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-8b1e62185e77>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict\u001b[0m\n\u001b[0m                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All that one liner is doing is going through our data and graphing it along with its associated color. See the video if you want to see it more broken down.\n",
        "\n",
        "Next, we want to graph our hyperplanes for the positive and negative support vectors, along with the decision boundary. In order to do this, we need at least two points for each to create a \"line\" which will be our hyperplane."
      ],
      "metadata": {
        "id": "PuiEAbJxx-7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we know what w and b are, we can use algebra to create a function that will return to us the value needed for our second feature (x2) to make the line:"
      ],
      "metadata": {
        "id": "bUKfTx9QyBF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperplane(x,w,b,v):\n",
        "            # v = (w.x+b)\n",
        "            return (-w[0]*x-b+v) / w[1]"
      ],
      "metadata": {
        "id": "sOZ0gzf6yDMz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up, we create some variables to house various data that we're going to reference:"
      ],
      "metadata": {
        "id": "nMEZthl-yGmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
        "hyp_x_min = datarange[0]\n",
        "hyp_x_max = datarange[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "rc6rkH5ByIQY",
        "outputId": "5b2170ff-11a5-426d-c89d-bde979c7319a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8f5c3bf1ebf3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatarange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_feature_value\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_feature_value\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhyp_x_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatarange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhyp_x_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatarange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our main goal here is to establish to what values we want to actually draw our hyperplanes.\n",
        "\n",
        "Now, let's graph our positive support vector hyperplane:"
      ],
      "metadata": {
        "id": "6iCx9j8jyTRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# w.x + b = 1\n",
        "# pos sv hyperplane\n",
        "psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
        "psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
        "self.ax.plot([hyp_x_min,hyp_x_max], [psv1,psv2], \"k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "y6T5nvZDyV1c",
        "outputId": "bd37a72e-665d-421a-ea5c-2b7c140cf0aa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hyp_x_min' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7c1765d61517>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# w.x + b = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# pos sv hyperplane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpsv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperplane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_x_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpsv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperplane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_x_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhyp_x_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyp_x_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpsv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hyp_x_min' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple e nough, we get the data for the first and second x2 values, then we graph them. Now we'll do the next two hyperplanes:"
      ],
      "metadata": {
        "id": "cAL77ExKydP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# w.x + b = -1\n",
        "        # negative sv hyperplane\n",
        "nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
        "nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
        "self.ax.plot([hyp_x_min,hyp_x_max], [nsv1,nsv2], \"k\")\n",
        "\n",
        "        # w.x + b = 0\n",
        "        # decision\n",
        "db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
        "db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
        "self.ax.plot([hyp_x_min,hyp_x_max], [db1,db2], \"g--\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "eP6Jz8xmyfbc",
        "outputId": "b619b29c-a0db-473f-eb2c-3f6a2185a1ed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hyp_x_min' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0a2d88e72d7b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# w.x + b = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;31m# negative sv hyperplane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnsv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperplane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_x_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnsv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperplane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_x_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhyp_x_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyp_x_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnsv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsv2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hyp_x_min' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, adding some code at the bottom for training, predicting, and visualizing:\n",
        "\n"
      ],
      "metadata": {
        "id": "7-A7cMgFyp_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "style.use('ggplot')\n",
        "\n",
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)\n",
        "    # train\n",
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        # { ||w||: [w,b] }\n",
        "        opt_dict = {}\n",
        "\n",
        "        transforms = [[1,1],\n",
        "                      [-1,1],\n",
        "                      [-1,-1],\n",
        "                      [1,-1]]\n",
        "\n",
        "        all_data = []\n",
        "        for yi in self.data:\n",
        "            for featureset in self.data[yi]:\n",
        "                for feature in featureset:\n",
        "                    all_data.append(feature)\n",
        "\n",
        "        self.max_feature_value = max(all_data)\n",
        "        self.min_feature_value = min(all_data)\n",
        "        all_data = None\n",
        "\n",
        "        # support vectors yi(xi.w+b) = 1\n",
        "\n",
        "\n",
        "        step_sizes = [self.max_feature_value * 0.1,\n",
        "                      self.max_feature_value * 0.01,\n",
        "                      # point of expense:\n",
        "                      self.max_feature_value * 0.001,\n",
        "                      ]\n",
        "\n",
        "\n",
        "\n",
        "        # extremely expensive\n",
        "        b_range_multiple = 2\n",
        "        # we dont need to take as small of steps\n",
        "        # with b as we do w\n",
        "        b_multiple = 5\n",
        "        latest_optimum = self.max_feature_value*10\n",
        "\n",
        "        for step in step_sizes:\n",
        "            w = np.array([latest_optimum,latest_optimum])\n",
        "            # we can do this because convex\n",
        "            optimized = False\n",
        "            while not optimized:\n",
        "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
        "                                   self.max_feature_value*b_range_multiple,\n",
        "                                   step*b_multiple):\n",
        "                    for transformation in transforms:\n",
        "                        w_t = w*transformation\n",
        "                        found_option = True\n",
        "                        # weakest link in the SVM fundamentally\n",
        "                        # SMO attempts to fix this a bit\n",
        "                        # yi(xi.w+b) >= 1\n",
        "                        #\n",
        "                        # #### add a break here later..\n",
        "                        for i in self.data:\n",
        "                            for xi in self.data[i]:\n",
        "                                yi=i\n",
        "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
        "                                    found_option = False\n",
        "                                    #print(xi,':',yi*(np.dot(w_t,xi)+b))\n",
        "\n",
        "                        if found_option:\n",
        "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
        "\n",
        "                if w[0] < 0:\n",
        "                    optimized = True\n",
        "                    print('Optimized a step.')\n",
        "                else:\n",
        "                    w = w - step\n",
        "\n",
        "            norms = sorted([n for n in opt_dict])\n",
        "            #||w|| : [w,b]\n",
        "            opt_choice = opt_dict[norms[0]]\n",
        "            self.w = opt_choice[0]\n",
        "            self.b = opt_choice[1]\n",
        "            latest_optimum = opt_choice[0][0]+step*2\n",
        "\n",
        "        for i in self.data:\n",
        "            for xi in self.data[i]:\n",
        "                yi=i\n",
        "                print(xi,':',yi*(np.dot(self.w,xi)+self.b))\n",
        "\n",
        "    def predict(self,features):\n",
        "        # sign( x.w+b )\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "        if classification !=0 and self.visualization:\n",
        "            self.ax.scatter(features[0], features[1], s=200, marker='*', c=self.colors[classification])\n",
        "        return classification\n",
        "\n",
        "    def visualize(self):\n",
        "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
        "\n",
        "        # hyperplane = x.w+b\n",
        "        # v = x.w+b\n",
        "        # psv = 1\n",
        "        # nsv = -1\n",
        "        # dec = 0\n",
        "        def hyperplane(x,w,b,v):\n",
        "            return (-w[0]*x-b+v) / w[1]\n",
        "\n",
        "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
        "        hyp_x_min = datarange[0]\n",
        "        hyp_x_max = datarange[1]\n",
        "\n",
        "        # (w.x+b) = 1\n",
        "        # positive support vector hyperplane\n",
        "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
        "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
        "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\n",
        "\n",
        "        # (w.x+b) = -1\n",
        "        # negative support vector hyperplane\n",
        "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
        "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
        "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\n",
        "\n",
        "        # (w.x+b) = 0\n",
        "        # positive support vector hyperplane\n",
        "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
        "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
        "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "data_dict = {-1:np.array([[1,7],\n",
        "                          [2,8],\n",
        "                          [3,8],]),\n",
        "\n",
        "             1:np.array([[5,1],\n",
        "                         [6,-1],\n",
        "                         [7,3],])}\n",
        "\n",
        "svm = Support_Vector_Machine()\n",
        "svm.fit(data=data_dict)\n",
        "\n",
        "predict_us = [[0,10],\n",
        "              [1,3],\n",
        "              [3,4],\n",
        "              [3,5],\n",
        "              [5,5],\n",
        "              [5,6],\n",
        "              [6,-5],\n",
        "              [5,8]]\n",
        "\n",
        "for p in predict_us:\n",
        "    svm.predict(p)\n",
        "\n",
        "svm.visualize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "-LZqnZdnytkw",
        "outputId": "17e85bbb-b521-4e64-ba61-bf7e1764017f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized a step.\n",
            "Optimized a step.\n",
            "Optimized a step.\n",
            "[1 7] : 1.271999999999435\n",
            "[2 8] : 1.271999999999435\n",
            "[3 8] : 1.0399999999995864\n",
            "[5 1] : 1.0479999999990506\n",
            "[ 6 -1] : 1.7439999999985962\n",
            "[7 3] : 1.0479999999990506\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}